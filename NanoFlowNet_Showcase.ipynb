{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "To get started you need to link your google drive with google colab in the files tab to the left.\n",
        "\n",
        "Upload [this](https://github.com/gemenerik/nanoflownet-cnns/blob/main/pretrained_models/nanoflownet/nanoflownet_unquantized.tflite) file (the neural network .tflite) to your main google drive directory.\n",
        "\n",
        "In the following code it is used in the Load Model part. In case you want to choose a different directory:\n",
        "\n",
        "```\n",
        "# Load TFLite model and allocate tensors\n",
        "tflite_model_path = '/content/drive/MyDrive/nanoflownet_unquantized.tflite'\n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
        "interpreter.allocate_tensors()\n",
        "```\n"
      ],
      "metadata": {
        "id": "bC9ciLHUJg-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Imports:\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from IPython.display import display, Image, Javascript\n",
        "import base64\n",
        "from PIL import Image as PILImage\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "from google.colab.output import eval_js"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0ldiECYIzdUU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define Functions:\n",
        "def take_photo_pair(quality=0.8, interval=20):  # interval is in milliseconds\n",
        "    js_code = f'''\n",
        "    async function takePhoto(quality, interval) {{\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'none';  // Set display to 'none' to hide the video element\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({{ video: true }});\n",
        "\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      return [video, stream];\n",
        "    }}\n",
        "\n",
        "    async function captureFrames(video, quality, interval, resolve) {{\n",
        "      const frames = [];\n",
        "      let frameCount = 0;\n",
        "\n",
        "      function captureFrame() {{\n",
        "        const canvas = document.createElement('canvas');\n",
        "        canvas.width = video.videoWidth;\n",
        "        canvas.height = video.videoHeight;\n",
        "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "\n",
        "        const dataUrl = canvas.toDataURL('image/jpeg', quality);\n",
        "        frames.push(dataUrl);\n",
        "        frameCount += 1;\n",
        "\n",
        "        if (frameCount >= 2) {{\n",
        "          resolve(frames);\n",
        "        }}\n",
        "      }}\n",
        "\n",
        "      setInterval(captureFrame, interval);\n",
        "    }}\n",
        "\n",
        "    takePhoto({quality}).then(([video, stream]) => {{\n",
        "      return new Promise((resolve) => {{\n",
        "        captureFrames(video, {quality}, {interval}, resolve);\n",
        "      }});\n",
        "    }});\n",
        "    '''\n",
        "\n",
        "    result = eval_js(js_code)\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def make_colorwheel():\n",
        "    RY = 15\n",
        "    YG = 6\n",
        "    GC = 4\n",
        "    CB = 11\n",
        "    BM = 13\n",
        "    MR = 6\n",
        "\n",
        "    ncols = RY + YG + GC + CB + BM + MR\n",
        "    colorwheel = np.zeros((ncols, 3))\n",
        "    col = 0\n",
        "\n",
        "    # RY\n",
        "    colorwheel[0:RY, 0] = 255\n",
        "    colorwheel[0:RY, 1] = np.floor(255 * np.arange(0, RY) / RY)\n",
        "    col = col + RY\n",
        "    # YG\n",
        "    colorwheel[col:col + YG, 0] = 255 - np.floor(255 * np.arange(0, YG) / YG)\n",
        "    colorwheel[col:col + YG, 1] = 255\n",
        "    col = col + YG\n",
        "    # GC\n",
        "    colorwheel[col:col + GC, 1] = 255\n",
        "    colorwheel[col:col + GC, 2] = np.floor(255 * np.arange(0, GC) / GC)\n",
        "    col = col + GC\n",
        "    # CB\n",
        "    colorwheel[col:col + CB, 1] = 255 - np.floor(255 * np.arange(CB) / CB)\n",
        "    colorwheel[col:col + CB, 2] = 255\n",
        "    col = col + CB\n",
        "    # BM\n",
        "    colorwheel[col:col + BM, 2] = 255\n",
        "    colorwheel[col:col + BM, 0] = np.floor(255 * np.arange(0, BM) / BM)\n",
        "    col = col + BM\n",
        "    # MR\n",
        "    colorwheel[col:col + MR, 2] = 255 - np.floor(255 * np.arange(MR) / MR)\n",
        "    colorwheel[col:col + MR, 0] = 255\n",
        "    return colorwheel\n",
        "\n",
        "\n",
        "def flow_uv_to_colors(u, v, convert_to_bgr=False):\n",
        "    flow_image = np.zeros((u.shape[0], u.shape[1], 3), np.uint8)\n",
        "    colorwheel = make_colorwheel()  # shape [55x3]\n",
        "    ncols = colorwheel.shape[0]\n",
        "    rad = np.sqrt(np.square(u) + np.square(v))\n",
        "    a = np.arctan2(-v, -u) / np.pi\n",
        "    fk = (a + 1) / 2 * (ncols - 1)\n",
        "    k0 = np.floor(fk).astype(np.int32)\n",
        "    k1 = k0 + 1\n",
        "    k1[k1 == ncols] = 0\n",
        "    f = fk - k0\n",
        "    for i in range(colorwheel.shape[1]):\n",
        "        tmp = colorwheel[:, i]\n",
        "        col0 = tmp[k0] / 255.0\n",
        "        col1 = tmp[k1] / 255.0\n",
        "        col = (1 - f) * col0 + f * col1\n",
        "        idx = rad <= 1\n",
        "        col[idx] = 1 - rad[idx] * (1 - col[idx])\n",
        "        col[~idx] = col[~idx] * 0.75  # out of range\n",
        "        ch_idx = 2 - i if convert_to_bgr else i\n",
        "        flow_image[:, :, ch_idx] = np.floor(255 * col)\n",
        "    return flow_image\n",
        "\n",
        "\n",
        "def flow_to_color(flow_uv, clip_flow=None, convert_to_bgr=False, flow_norm=None):\n",
        "    assert flow_uv.ndim == 3, \"input flow must have three dimensions\"\n",
        "    assert flow_uv.shape[2] == 2, \"input flow must have shape [H,W,2]\"\n",
        "    if clip_flow is not None:\n",
        "        flow_uv = np.clip(flow_uv, 0, clip_flow)\n",
        "    u = flow_uv[:, :, 0]\n",
        "    v = flow_uv[:, :, 1]\n",
        "\n",
        "    if flow_norm is not None:\n",
        "        assert flow_norm > 0\n",
        "    else:\n",
        "        rad = np.sqrt(np.square(u) + np.square(v))\n",
        "        rad_max = np.max(rad)\n",
        "        epsilon = 1e-5\n",
        "        flow_norm = rad_max + epsilon\n",
        "    u = u / flow_norm\n",
        "    v = v / flow_norm\n",
        "    return flow_uv_to_colors(u, v, convert_to_bgr)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "oJQhrop6JAk6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load Model:\n",
        "# Load TFLite model and allocate tensors\n",
        "tflite_model_path = '/content/drive/MyDrive/nanoflownet_unquantized.tflite'\n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors details\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OpSQ6CgSKtGu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Execute NanoFlowNet:\n",
        "# Continuously capture and display images\n",
        "try:\n",
        "    while True:\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Capture image pair\n",
        "        frames = take_photo_pair()\n",
        "\n",
        "        # Process and display each frame\n",
        "        for i, frame_data in enumerate(frames):\n",
        "            # Decode base64 image\n",
        "            img_data = base64.b64decode(frame_data.split(',')[1])\n",
        "\n",
        "            # Convert to grayscale and resize\n",
        "            frame = PILImage.open(BytesIO(img_data)).convert('L')\n",
        "            frame = frame.resize((input_details[0]['shape'][2], input_details[0]['shape'][1]))\n",
        "\n",
        "            # Preprocess the frame\n",
        "            preprocessed_frame = np.array(frame)[:, :, np.newaxis]\n",
        "            preprocessed_frame = np.expand_dims(preprocessed_frame, axis=0).astype(input_details[0]['dtype'])\n",
        "\n",
        "            # Run inference\n",
        "            interpreter.set_tensor(input_details[0]['index'], preprocessed_frame)\n",
        "            interpreter.invoke()\n",
        "\n",
        "            output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "            output_image = np.squeeze(output_data)\n",
        "\n",
        "            # Visualizing optical flow using provided functions\n",
        "            u = output_image[:, :, 0]\n",
        "            v = output_image[:, :, 1]\n",
        "            flow_image = flow_to_color(output_image, convert_to_bgr=True)\n",
        "\n",
        "            # Clear the previous output\n",
        "            clear_output(wait=True)\n",
        "\n",
        "            # Display the flow image using matplotlib\n",
        "            plt.imshow(flow_image)\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "\n",
        "        # Control the frame rate\n",
        "        elapsed_time = time.time() - start_time\n",
        "        time_to_sleep = max(0, 1 / 10 - elapsed_time)\n",
        "        time.sleep(time_to_sleep)\n",
        "\n",
        "except Exception as err:\n",
        "    print(str(err))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "pMuhooeoLukJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}